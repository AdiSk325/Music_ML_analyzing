{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AdiSk325/Music_ML_analyzing/blob/master/Music_Data_Augumentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a-WgfF4AZAp_"
   },
   "source": [
    "Aby zacząć pracę w Colab należy podłączyć Google Drive i wykonać poniższą komórkę"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "KFh-pDnuYXMc",
    "outputId": "70630cba-9601-4596-db0a-d4392d0e6ba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\users\\skutn\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.10.2)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\skutn\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from soundfile) (1.12.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\skutn\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.19)\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "joqH3pGOYtJe",
    "outputId": "bc9148c0-f347-43fa-c15a-bb824261d597"
   },
   "outputs": [],
   "source": [
    "#cd \"/content/drive/My Drive/GIT/Music_ML_analyzing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZjP5_KoUUJNr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate=44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZkRTjnXpXM_U"
   },
   "outputs": [],
   "source": [
    "def transpose_wav_file(path_input, path_output, n_steps):\n",
    "  x, sr = librosa.load(path_input, sr=sample_rate)\n",
    "  y = librosa.effects.pitch_shift(x, sr, n_steps=n_steps)\n",
    "  sf.write(path_output, y, sr, 'PCM_16')\n",
    "  #print(f'File {path_input} was transposed to file {path_output}')\n",
    "  return None\n",
    "    \n",
    "def chtime_wav_file(path_input, path_output, rate):\n",
    "                           \n",
    "  x, sr = librosa.load(path_input, sr=sample_rate)\n",
    "  y = librosa.effects.time_stretch(x, rate)\n",
    "  sf.write(path_output, y, sr, 'PCM_16')\n",
    "  #print(f'File {path_input} was chtime to file {path_output}')\n",
    "        \n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NfVO-m_yT_qa"
   },
   "outputs": [],
   "source": [
    "HOME_DIR = '.'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'data')\n",
    "INPUT_DIR = DATA_DIR\n",
    "OUTPUT_DIR = os.path.join(HOME_DIR,'augument_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "F9Y_3g8TT_qe",
    "outputId": "be9372f7-6d1c-4898-f318-85f806521ff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\GIT\\Music_ML_analyzing\\data\n",
      "E:\\GIT\\Music_ML_analyzing\\augument_data\n"
     ]
    }
   ],
   "source": [
    "print(os.path.realpath(INPUT_DIR))\n",
    "print(os.path.realpath(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kk5z2_dT_qj"
   },
   "outputs": [],
   "source": [
    "def clone_input_dir_structure(INPUT_DIR, OUTPUT_DIR):\n",
    "    for dirpath, dirnames, filenames in os.walk(INPUT_DIR):\n",
    "        structure = os.path.realpath(os.path.join(OUTPUT_DIR, dirpath[len(INPUT_DIR)+1:]))\n",
    "        if not os.path.isdir(structure):\n",
    "            os.mkdir(structure)\n",
    "        else:\n",
    "            print(f\"{structure}\\nThis folder does already exits! \\n ----------------------------------------------- \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YgqMFDutT_qm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clone_input_dir_structure(INPUT_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCTfIJd6T_qo"
   },
   "outputs": [],
   "source": [
    "def create_new_data_from_raw_input(INPUT_DIR, OUTPUT_DIR):\n",
    "    for dirpath, dirnames, filenames in os.walk(INPUT_DIR):\n",
    "            for filename in filenames: \n",
    "                if '.wav' in filename:\n",
    "                    output_path = os.path.join(OUTPUT_DIR, dirpath[len(INPUT_DIR)+1:], filename)\n",
    "                    transpose_wav_file(path_input = os.path.join(dirpath, filename),\n",
    "                                               path_output = output_path,\n",
    "                                               n_steps=0)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KArqviJcT_qr"
   },
   "outputs": [],
   "source": [
    "create_new_data_from_raw_input(INPUT_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UzgPghxHT_qt"
   },
   "outputs": [],
   "source": [
    "def generate_transpose_matrix(labels):\n",
    "    result_mtx = pd.DataFrame(labels)\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels.append(labels.pop(0))\n",
    "        result_mtx[idx+1] = pd.Series(labels)\n",
    "    return result_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCr5Sl0kT_qw"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(OUTPUT_DIR, 'labels')):\n",
    "    os.mkdir(os.path.join(OUTPUT_DIR, 'labels'))\n",
    "\n",
    "for label in ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']:\n",
    "    if not os.path.exists(os.path.join(OUTPUT_DIR, 'labels', label)):\n",
    "        os.mkdir(os.path.join(OUTPUT_DIR, 'labels', label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O1_zMYX9T_qz"
   },
   "source": [
    "Transponujemy nagrania do odpowiednich tonacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ykKbIKhtT_qz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "transpose_matrix = generate_transpose_matrix(labels)\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(os.path.join(OUTPUT_DIR, 'chords', 'major')):\n",
    "        for filename in filenames:\n",
    "            \n",
    "            filename_tonation = filename.split('.')[0]\n",
    "            transpose_row = transpose_matrix[transpose_matrix[0] == filename_tonation]\n",
    "            \n",
    "            for step in transpose_row.columns:\n",
    "                output_path = os.path.join(OUTPUT_DIR, 'labels', transpose_row[step].values[0], (dirpath.split(os.path.sep))[-2] + '_' + (dirpath.split(os.path.sep))[-1] + '_from_{}'.format(filename_tonation) + '.wav' )\n",
    "                transpose_wav_file(path_input = os.path.join(dirpath, filename),\n",
    "                                           path_output= output_path, \n",
    "                                           n_steps=step)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcbHkNeAT_q1"
   },
   "source": [
    "Generujemy dane w różnych tempach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9y3dxbLaT_q2"
   },
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(os.path.join(OUTPUT_DIR, 'labels')):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        filename_wo_wav = filename.split('.')[0]\n",
    "                \n",
    "        for time_rate in np.linspace(0.75, 1.25, 11):\n",
    "            \n",
    "            output_path = os.path.join(dirpath, filename_wo_wav + '_{}'.format(str(time_rate).replace('.','_')) + '.wav')\n",
    "            chtime_wav_file(path_input = os.path.join(dirpath, filename),\n",
    "                                    path_output= output_path,\n",
    "                                    rate = time_rate)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za pomocą  `pd.to_pickle` zbieramy wygenerowane dane w jeden plik z danymi oraz z etykietami danych. Tak przygotowane dane  są gotowe do obróbki przed trenowaniem modelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "2it [00:38, 19.31s/it]\n",
      "3it [01:19, 25.73s/it]\n",
      "4it [01:59, 30.11s/it]\n",
      "5it [02:39, 32.95s/it]\n",
      "6it [03:04, 30.50s/it]\n",
      "7it [03:38, 31.62s/it]\n",
      "8it [04:17, 34.04s/it]\n",
      "9it [04:58, 36.01s/it]\n",
      "10it [05:37, 36.95s/it]\n",
      "11it [06:17, 37.75s/it]\n",
      "12it [06:56, 38.08s/it]\n",
      "13it [07:35, 35.06s/it]\n"
     ]
    }
   ],
   "source": [
    "data_raw = []\n",
    "labels_raw = []\n",
    "for dirpath, dirnames, filenames in tqdm(os.walk(os.path.join(OUTPUT_DIR,'labels'))):\n",
    "    for filename in filenames:\n",
    "        sample_array, sample_rate = librosa.load(os.path.join(dirpath, filename))\n",
    "        data_raw.append(sample_array)\n",
    "        labels_raw.append(dirpath.split(os.path.sep)[-1])\n",
    "\n",
    "data_raw = np.array(data_raw)\n",
    "pd.to_pickle(data_raw, os.path.join(OUTPUT_DIR,'labels', 'audio_data_raw.pkl'))\n",
    "pd.to_pickle(labels_raw, os.path.join(OUTPUT_DIR,'labels', 'audio_labels_raw.pkl'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Music_Data_Augumentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
