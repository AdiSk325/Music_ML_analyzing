{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AdiSk325/Music_ML_analyzing/blob/master/CNN_tonation_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [#1]  Muzyka w sieci (neuronowej)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Zadanie \n",
    "\n",
    "> ### Budowa sieci neuronowej rozpoznającej tonację zagranego akordu\n",
    "> 1. Wczytanie przygotowanych **danych**\n",
    "> 2. Obróbka przy pomocy biblioteki `librosa` oraz dwóch **transformacji danych dźwiękowych**\n",
    "> 3. Budowa **sieci neuronowej** z wykorzystaniem biblioteki `tensorflow.keras` dla każdej z transformacji i porównanie wyników"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na początku było ...\n",
    "\n",
    "Cześć!\n",
    "\n",
    "W tym artykule chcę zaprezentować, jak wystartować z budową modelu Machine Learning, stosując **konwolucyjne sieci neuronowe**, który karmi się muzyką! Ale dlaczego miałbym karmić mój model muzyką i co on na jej temat miałby mi opowiedzieć?   \n",
    "Zanim opowiem w kilku słowach skąd taki pomysł, zobaczcie z jakich **bibliotek** będę korzystał i jaki jest **główny cel** tego artykułu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "418KqlOzfVVP",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Poruszanie się po katalogach i plikach\n",
    "import os\n",
    "\n",
    "#Przygotowanie danych do modelowania\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "#Analiza dźwięku zamknięta w pythonową bibliotekę\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "#Prezentacja dźwięku w postaci wykresów\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Przygotowanie próbek train i test oraz metryka sukcesu\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Progress Bar\n",
    "from tqdm import tqdm \n",
    "\n",
    "#Keras w kilku krokach pozwala zbudować niezłą sieć konwolucyjną\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CEL\n",
    ">Zawiodę Cię, Drogi Czytelniku, już na samym początku tego artykułu (jeśli oczekiwałeś czegoś innego, szkoda czasu na czytanie do końca). Celem tego zadania **nie jest rozwiązanie żadnego skomplikowanego problemu**, gdyż proponowana **sieć neuronowa** w tym przypadku to przysłowiowa armata wycelowana w irytującą muchę krążącą po pokoju.    \n",
    ">\n",
    ">Natomiast w tym wprowadzeniu chcę poruszyć w praktyce dwa zagadnienia: \n",
    "1. Jakie kroki w **obróbce danych audio** należy podjąć, aby przygotować je do trenowania sieci?\n",
    "2. Jak przygotowanie danych może wpłynąć na wynik zbudowanego modelu?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPEc6cWVfVVN"
   },
   "source": [
    "\n",
    "\n",
    "Od wielu lat moje zainteresowania kręcą się wokół szeroko pojętej muzyki. Wiem, że w ogólności brzmi to jak oklepany frazes, bo przecież każdy zapytany na ulicy o swoje zainteresowania w pośpiechu odpowie -- \"Muzyka!\". W takim razie chciałbym nieco doprecyzować, czym jest moje \"interesowanie się muzyką\".\n",
    "\n",
    "Po pierwsze, najprostsze i najpopularniejsze, to słuchanie różnej maści wykonawców i stylów. Poczynając od muzyki klasycznej (tak, mam 27 lat i lubię posłuchać Bacha), przez muzykę chóralną i liturgiczną różnych okresów, do współczesnych brzmień muzyki popularnej. I tutaj też dość szeroko, bo w moim domu usłyszycie zarówno mądry tekstowo (w subiektywnym odczuciu) polski rap oraz ciężkie brzmienie skandynawskich gitar na tle orkiestry symfonicznej. Także niezły kocioł, ku uciesze sąsiadów :)\n",
    "\n",
    "Po drugie, to kilka życiowych przygód instrumentalnych i wokalnych. Domowy zwierzyniec instrumentów muzycznych otwierają dwie gitary, klasyczna i akustyczna, ukulele, znajdzie się również tamburyn i sławny na całym świecie trójkąt. I dwie harmonijki ustne? Albo tylko jedna? Nie umiem się doliczyć. W rodzinnym domu, zakurzona gitara basowa pamięta czasy gimnazjalnej kapeli (teraz ani kapeli, ani gimnazjum ;/). W tamtym czasie powstało kilka bluesowych ballad i bardziej skocznych kawałków, z których żaden nie wyszedł poza mury podziemnej sali prób. Obecnie, wszystkie szarpane, dęte i perkusyjne zwierzaki zaległy w szafach i kątach, by ustąpić miejsca największemu spośród nich -- mowa tu o pianinie cyfrowym dumnie eksponowanym w centralnym miejscu w mieszkaniu. To dzięki niemu moja pasja do muzyki jest aktualnie w rozkwicie i kieruje mnie do zmierzenia się z królem muzycznego ogrodu, jakim są niewątpliwie organy piszczałkowe. Ale to narazie mglista przyszłość, więc nie miejsce i czas, aby więcej o nich opowiadać. Upomnijcie się za jakiś czas :).\n",
    "\n",
    "Wreszcie, zbliżając się do istoty tego artykułu, muzyka fascynuje mnie od swojej *t e c h n i c z n e j* strony. Od jej podstawowych zasad wykładanych w ogródkach i przedszkolach muzycznych całego świata, do matematycznych (często mocno akademickich) fundamentów cyfrowej obróbki dźwięku i zrozumienia, co dokładnie w \"muzycznej trawie piszczy\". \n",
    "\n",
    "Nie będę prawił poematów na temat muzyki, gdyż wystarczająco wielu wybitnych poetów urodziła nasza ziemia. Powiem tyle, ja znajduję w niej tak wiele inspiracji, że wreszcie przyszedł czas żeby się nimi podzielić. \n",
    "> **[Eviva l'arte](https://wolnelektury.pl/katalog/lektura/eviva-l-arte.html)**   \n",
    ">\n",
    "> ...   \n",
    "> *I chociaż życie nasze nic nie warte:    \n",
    "> Eviva l'arte!*\n",
    ">\n",
    "> `Kazimierz Przerwa-Tetmajer`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DercgMHUfVVO"
   },
   "source": [
    "Zdefiniujmy tylko ścieżkę do katalogu z danymi i... możemy zaczynać!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHiMVtOOfVVS"
   },
   "outputs": [],
   "source": [
    "HOME_DIR = '.'\n",
    "DATA_DIR = os.path.join(HOME_DIR, 'augument_data', 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCvsNlvrfVVU"
   },
   "source": [
    "### Przygotowanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9f0De3RyhcKI"
   },
   "source": [
    "Dane w modelach Machine Learning (i nie tylko) to podstawa owocnej pracy. Na potrzeby tego artykułu przygotowałem surowe pliki .wav, które zawierają nagrania akordów durowych w postaci zasadniczej i pierwszym przewrocie.       \n",
    "\n",
    "> **Sumaryczna długość nagrań wynosi aż 1 godzinę 34 minuty i 14 sekund.**\n",
    "\n",
    "Nie oznacza to, że spędziłem pół dnia przy klawiaturze pianina i komputerze, nagrywając melodycznie brzmiące akordy -- cierpliwość Małżonki i sąsiadów ma swoje granice, a takie zachowanie bezapelacyjnie znalazłoby się poza tymi granicami. O tym, w jaki sposób ze skromnych kilkunastu krótkich nagrań stworzyć dane gotowe do uczenia maszynowego znajdziecie w moim **kolejnym artykule** (póki artykuł się pisze zapraszam na GIT'a) - **[TUTAJ](https://github.com/AdiSk325/Music_ML_analyzing)**.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_gwqUqSfVVV"
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_pickle(os.path.join(DATA_DIR, 'audio_data_raw.pkl'))\n",
    "labels_raw = pd.read_pickle(os.path.join(DATA_DIR, 'audio_labels_raw.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m03djc6QmuLr"
   },
   "source": [
    "Powyższy plik zajmuje prawie 0.5 GB pamięci. Zajmowanie się muzyką i Data Science jednocześnie wymaga duuuużo miejsca. A jak policzyłem długość wszystkich plików? Wygląda to tak: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KWS0G2TklokG",
    "outputId": "d18dc676-8ba8-4256-d084-598368d70db7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:47:07'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate = 44100\n",
    "sec = int(np.array([len(sample) for sample in data_raw]).sum()/(sample_rate))\n",
    "str(datetime.timedelta(seconds=sec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To dobry moment, żeby opowiedzieć przez chwilę o `sample rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "V5mq24cefVVY",
    "outputId": "e50498ab-2826-4844-a9e5-8f3ee72e0f59"
   },
   "outputs": [],
   "source": [
    "def adjust_samples_len(samples):\n",
    "    \"\"\" Funkcja wyrównująca długość przygotowanych ścieżek do najdłuższej ścieżki spośród zadanych\"\"\"\n",
    "    \n",
    "    max_time_in_sec = max([len(sample) for sample in data_raw])/sample_rate\n",
    "    print('Najdłuższa ścieżka trwa {} s.'.format(round(max_time_in_sec,2)))\n",
    "    \n",
    "    result_lst = []\n",
    "    for sample in samples:\n",
    "        result_lst.append(np.pad(sample, (0, int(max_time_in_sec*sample_rate - len(sample))), 'constant'))\n",
    "      \n",
    "    return np.array(result_lst)\n",
    "\n",
    "data = adjust_samples_len(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wobilLkwfVVb"
   },
   "outputs": [],
   "source": [
    "labels = pd.factorize(labels_raw)[0]\n",
    "labels_names = pd.factorize(labels_raw)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpJrJ87FfVVg"
   },
   "source": [
    "### Kilka słów o muzyce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[YouTube](https://www.youtube.com/watch?v=spUNpyF58BY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data_raw[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.stft(data_raw[0], n_fft=2**12, win_length=2**7).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = data_raw[1], 22050\n",
    "freqs = librosa.core.fft_frequencies(sr, n_fft=2**10)\n",
    "S = np.abs((librosa.stft(y, n_fft=2**10, win_length=2**9)).real)\n",
    "harms = [1, 1/2, 1/3, 1/4, 1/5, 1/6]\n",
    "weights = [1,1,1,1,1,1]\n",
    "S_sal = librosa.amplitude_to_db(librosa.salience(S, freqs, harms, weights, fill_value=0), ref=np.max)\n",
    "print(S_sal.shape)\n",
    "\n",
    "librosa.display.specshow(S_sal, y_axis='log', sr=sr)\n",
    "plt.colorbar(format='%+2.0f dB');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 951
    },
    "colab_type": "code",
    "id": "xH95xmiBfVVg",
    "outputId": "d1572542-ad73-47cf-f7ec-5a6a496a37a9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(45, 30))\n",
    "for i in range(12):\n",
    "    y = data_raw[168*i]\n",
    "    plt.subplot(4,3,i+1)\n",
    "    #C = librosa.amplitude_to_db(np.abs(librosa.stft(y, n_fft=2**9)))\n",
    "    C = librosa.amplitude_to_db(np.abs(librosa.stft(y, n_fft=2**10, win_length=2**9).real))\n",
    "    librosa.display.specshow(C, y_axis='log')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Name: {}'.format(labels_names[labels[168*i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SvtgqOgVfVVj",
    "outputId": "05fd5465-f564-40ce-e677-8219f7903e54"
   },
   "outputs": [],
   "source": [
    "magnitude_raw = []\n",
    "for sample in tqdm(data):\n",
    "    magnitude_raw.append(librosa.amplitude_to_db(np.abs(librosa.stft(y, n_fft=2**10, win_length=2**9).real)))\n",
    "magnitude_raw = np.array(magnitude_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "colab_type": "code",
    "id": "4snVCCj3fVVl",
    "outputId": "cc30741e-b0c0-4285-d882-c0438608abd2"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "for i in range(12):\n",
    "    y = data[168*i]\n",
    "    plt.subplot(4,3,i+1)\n",
    "    C = librosa.feature.chroma_cqt(y)\n",
    "    librosa.display.specshow(C, y_axis='chroma')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Name: {}'.format(labels_names[labels[168*i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4st-wgRzfVVo",
    "outputId": "0ac684da-5d7e-4775-f0cd-72ee24a95372"
   },
   "outputs": [],
   "source": [
    "chroma_cqt_raw = []\n",
    "for sample in tqdm(data):\n",
    "    chroma_cqt_raw.append(librosa.feature.chroma_cqt(sample))\n",
    "chroma_cqt_raw = np.array(chroma_cqt_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KFYhYuR9fVVq"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(magnitude_raw, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWKqjyjnfVVt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if y_train.ndim == 1: y_train = to_categorical(y_train)\n",
    "if y_test.ndim == 1: y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-tY4JWAfVVv"
   },
   "outputs": [],
   "source": [
    "x,y,z = X_train.shape\n",
    "X_train = X_train.reshape(x,y,z,1)\n",
    "\n",
    "x,y,z = X_test.shape\n",
    "X_test = X_test.reshape(x,y,z,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UcdOc4dsfVVx"
   },
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uhKqWW02fVVz",
    "outputId": "a67a526f-aa23-4538-c439-7b3a9c586e4c"
   },
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xKfKelO5fVV1"
   },
   "outputs": [],
   "source": [
    "def get_cnn_for_magnitude(input_shape, num_classes):\n",
    "    return Sequential([\n",
    "    Conv2D(filters=128, kernel_size=(50,50), strides=(3,3), activation='relu', input_shape=input_shape),\n",
    "    Conv2D(filters=64,  kernel_size=(30,30),  strides=(2,2), activation='relu', input_shape=input_shape), \n",
    "    MaxPool2D(),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv2D(filters=32, kernel_size=(4,4), activation='relu', input_shape=input_shape),\n",
    "    MaxPool2D(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "    \n",
    "def get_cnn_for_chroma_cqt(input_shape, num_classes):\n",
    "    return Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(8,8), activation='relu', input_shape=input_shape),\n",
    "    Conv2D(filters=32, kernel_size=(4,4), activation='relu', input_shape=input_shape), \n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dropout(0.4),    \n",
    "            \n",
    "    Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "  \n",
    "def train_model(model, X_train, y_train, params_fit={}):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    #logdir = os.path.join(HOME_DIR, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    #tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "  \n",
    "    model.fit(\n",
    "          X_train,\n",
    "          y_train,\n",
    "          batch_size = params_fit.get('batch_size', 64),\n",
    "          epochs = params_fit.get('epochs', 5),\n",
    "          verbose=params_fit.get('verbose',1),\n",
    "          validation_data = params_fit.get('validation_data', (X_train, y_train)),\n",
    "          #callbacks= [tensorboard_callback]\n",
    "          )\n",
    "    \n",
    "def predict(model_trained, X_test, y_test, scoring=accuracy_score):\n",
    "    y_test_norm = np.argmax(y_test, axis=1)\n",
    "    y_pred_prob = model_trained.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    return scoring(y_test_norm, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "Fcx6vV6LfVV4",
    "outputId": "6cc0b1ec-6571-45e2-df61-e94ed445fe50",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_cnn_for_magnitude(input_shape, num_classes)\n",
    "#model = get_cnn_for_chroma_cqt(input_shape, num_classes)\n",
    "train_model(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "53DQmfR5fVV6",
    "outputId": "46874e12-231e-4fe6-e94a-b9ee55eadbd1"
   },
   "outputs": [],
   "source": [
    "predict(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "JSWXi-8CfVV8",
    "outputId": "e060ef51-9898-4141-c94e-a28901589fd3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(labels_names[np.argmax(model.predict(X_test)[0])])\n",
    "print(labels_names[y_test[0].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "n1jirirEfVWA",
    "outputId": "817a0141-6d06-4860-dcba-b5666c16dffa"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "CNN_tonation_recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
